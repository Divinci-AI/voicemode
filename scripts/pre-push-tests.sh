#!/bin/bash
# Pre-push test suite for Voice Coordination System
# This script runs comprehensive tests before pushing changes

set -e  # Exit on any error

echo "üöÄ Running Voice Coordination System Pre-Push Test Suite"
echo "=" $(printf '=%.0s' {1..60})

# Colors for output
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# Test results tracking
TESTS_PASSED=0
TESTS_FAILED=0
TESTS_SKIPPED=0

# Function to run test and track results
run_test() {
    local test_name="$1"
    local test_command="$2"
    local allow_failure="${3:-false}"
    
    echo -e "\n${YELLOW}üß™ Running: $test_name${NC}"
    echo "Command: $test_command"
    
    if eval "$test_command"; then
        echo -e "${GREEN}‚úÖ PASSED: $test_name${NC}"
        ((TESTS_PASSED++))
        return 0
    else
        if [ "$allow_failure" == "true" ]; then
            echo -e "${YELLOW}‚ö†Ô∏è SKIPPED: $test_name (allowed to fail)${NC}"
            ((TESTS_SKIPPED++))
            return 0
        else
            echo -e "${RED}‚ùå FAILED: $test_name${NC}"
            ((TESTS_FAILED++))
            return 1
        fi
    fi
}

# Function to check dependencies
check_dependencies() {
    echo -e "\n${YELLOW}üîç Checking Dependencies${NC}"
    
    # Check Python version
    python_version=$(python --version 2>&1)
    echo "Python: $python_version"
    
    # Check required packages
    required_packages=("pytest" "asyncio" "websockets" "fastapi" "uvicorn")
    for package in "${required_packages[@]}"; do
        if python -c "import $package" 2>/dev/null; then
            echo "‚úÖ $package available"
        else
            echo "‚ùå $package missing"
            echo "Install with: pip install $package"
            return 1
        fi
    done
    
    # Check macOS say command (for E2E tests)
    if command -v say >/dev/null 2>&1; then
        echo "‚úÖ macOS say command available"
        SAY_AVAILABLE=true
    else
        echo "‚ö†Ô∏è macOS say command not available (E2E speech tests will be simulated)"
        SAY_AVAILABLE=false
    fi
    
    return 0
}

# Function to run static analysis
run_static_analysis() {
    echo -e "\n${YELLOW}üìä Running Static Analysis${NC}"
    
    # Code quality checks
    run_test "Black Code Formatting Check" \
        "python -m black --check --diff *.py tests/ || echo 'Run: python -m black *.py tests/ to fix formatting'"
    
    run_test "Import Sorting Check" \
        "python -m isort --check-only --diff *.py tests/ || echo 'Run: python -m isort *.py tests/ to fix imports'"
    
    run_test "Flake8 Linting" \
        "python -m flake8 *.py tests/ --max-line-length=88 --extend-ignore=E203,W503,F401" \
        "true"  # Allow to fail
    
    run_test "Security Scan (Bandit)" \
        "python -m bandit -r . -f json -o bandit-report.json --exclude ./tests,./venv,./build,./dist || echo 'Security issues found - check bandit-report.json'" \
        "true"  # Allow to fail
}

# Function to run unit tests
run_unit_tests() {
    echo -e "\n${YELLOW}üî¨ Running Unit Tests${NC}"
    
    run_test "Voice Coordination Server Unit Tests" \
        "python -m pytest tests/test_coordination_server.py -v --tb=short --junitxml=test-reports/server-unit-tests.xml"
    
    run_test "Client and Hook Unit Tests" \
        "python -m pytest tests/test_client_hook.py -v --tb=short --junitxml=test-reports/client-unit-tests.xml"
    
    run_test "All Unit Tests with Coverage" \
        "python -m pytest tests/test_*.py -v --cov=. --cov-report=xml:test-reports/coverage.xml --cov-report=html:test-reports/htmlcov --tb=short" \
        "true"  # Allow to fail if coverage tools not available
}

# Function to run integration tests
run_integration_tests() {
    echo -e "\n${YELLOW}üîó Running Integration Tests${NC}"
    
    # Test system imports and basic functionality
    run_test "System Import Validation" \
        "python -c '
import sys; 
sys.path.append(\".\");
from voice_coordination_server import VoiceCoordinationServer;
from claude_code_voice_hook import VoiceCoordinationClient;
print(\"‚úÖ All core modules import successfully\")
'"
    
    # Test configuration validation
    run_test "Configuration Validation" \
        "python -c '
from voice_coordination_server import VoiceCoordinationServer;
server = VoiceCoordinationServer(port=8769);
status = server.get_coordination_status();
assert \"total_agents\" in status;
print(\"‚úÖ Server configuration valid\")
'"
}

# Function to run E2E tests
run_e2e_tests() {
    echo -e "\n${YELLOW}üé≠ Running End-to-End Tests${NC}"
    
    if [ "$SAY_AVAILABLE" == "true" ]; then
        echo "üîä macOS say() available - running full E2E tests with speech"
        run_test "E2E Voice Coordination Tests" \
            "python -m pytest tests/test_e2e_voice_coordination.py -v -m e2e --tb=short --junitxml=test-reports/e2e-tests.xml" \
            "true"  # Allow to fail as E2E tests are complex
    else
        echo "üîá macOS say() not available - running E2E tests with speech simulation"
        run_test "E2E Voice Coordination Tests (Simulated)" \
            "python -m pytest tests/test_e2e_voice_coordination.py -v -m e2e --tb=short --junitxml=test-reports/e2e-tests-sim.xml" \
            "true"  # Allow to fail
    fi
}

# Function to run system tests
run_system_tests() {
    echo -e "\n${YELLOW}‚öôÔ∏è Running System Tests${NC}"
    
    # Test the full coordination system
    run_test "Full System Integration Test" \
        "timeout 30s python test_voice_coordination_system.py || echo 'System test completed with timeout'" \
        "true"  # Allow to fail due to timing/environment issues
}

# Function to generate test report
generate_test_report() {
    echo -e "\n${YELLOW}üìä Generating Test Report${NC}"
    
    # Create test reports directory if it doesn't exist
    mkdir -p test-reports
    
    # Generate summary report
    cat > test-reports/pre-push-summary.txt << EOF
Voice Coordination System Pre-Push Test Summary
================================================
Date: $(date)
Branch: $(git branch --show-current 2>/dev/null || echo "unknown")
Commit: $(git rev-parse HEAD 2>/dev/null || echo "unknown")

Test Results:
- Tests Passed: $TESTS_PASSED
- Tests Failed: $TESTS_FAILED  
- Tests Skipped: $TESTS_SKIPPED
- Total Tests: $((TESTS_PASSED + TESTS_FAILED + TESTS_SKIPPED))

Success Rate: $(echo "scale=1; $TESTS_PASSED * 100 / ($TESTS_PASSED + $TESTS_FAILED)" | bc -l 2>/dev/null || echo "N/A")%

Environment:
- Python: $(python --version)
- Platform: $(uname -s) $(uname -r)
- macOS say() available: $SAY_AVAILABLE

Files in test-reports/:
$(ls -la test-reports/ 2>/dev/null | tail -n +2 || echo "No additional test files")
EOF

    echo "üìÑ Test report saved to: test-reports/pre-push-summary.txt"
}

# Main execution
main() {
    echo "Starting pre-push test suite at $(date)"
    
    # Create test reports directory
    mkdir -p test-reports
    
    # Check dependencies first
    if ! check_dependencies; then
        echo -e "${RED}‚ùå Dependency check failed. Please install missing dependencies.${NC}"
        exit 1
    fi
    
    # Run test suites
    run_static_analysis
    run_unit_tests
    run_integration_tests
    run_e2e_tests
    run_system_tests
    
    # Generate report
    generate_test_report
    
    # Final summary
    echo -e "\n" "=" $(printf '=%.0s' {1..60})
    echo -e "${YELLOW}üìä FINAL TEST SUMMARY${NC}"
    echo -e "Tests Passed: ${GREEN}$TESTS_PASSED${NC}"
    echo -e "Tests Failed: ${RED}$TESTS_FAILED${NC}"
    echo -e "Tests Skipped: ${YELLOW}$TESTS_SKIPPED${NC}"
    
    if [ $TESTS_FAILED -eq 0 ]; then
        echo -e "\n${GREEN}üéâ ALL CRITICAL TESTS PASSED! Ready to push.${NC}"
        exit 0
    else
        echo -e "\n${RED}üí• $TESTS_FAILED CRITICAL TESTS FAILED!${NC}"
        echo -e "${RED}Please fix failing tests before pushing.${NC}"
        echo -e "\nFor detailed results, check:"
        echo -e "- test-reports/pre-push-summary.txt"
        echo -e "- Individual test report files in test-reports/"
        exit 1
    fi
}

# Run main function
main "$@"